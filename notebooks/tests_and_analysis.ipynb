{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librairies loading\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks created :770\n"
     ]
    }
   ],
   "source": [
    "# data loading\n",
    "current_path = os.getcwd()\n",
    "path = os.path.join(current_path, '..', 'data', 'raw_data', 'cga-canal-canalsat-web.pdf')\n",
    "\n",
    "loader = PyPDFLoader(path)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000,\n",
    "                                               chunk_overlap = 200,\n",
    "                                               separators = [\"\\n\\n\", \"\\n\", \" \", \"\"])\n",
    "\n",
    "chunks =text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Number of chunks created :{len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayen\\AppData\\Local\\Temp\\ipykernel_101212\\940450228.py:17: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_db.persist() # for reproductibility\n"
     ]
    }
   ],
   "source": [
    "# embeddings\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "model_kwargs = {'device' : 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings' : True}\n",
    "\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "                    model_name = model_name,\n",
    "                    model_kwargs = model_kwargs,\n",
    "                    encode_kwargs = encode_kwargs)\n",
    "\n",
    "path_chroma_db = os.path.join(current_path, '..', 'data', 'chroma_db')\n",
    "chroma_db = Chroma.from_documents(documents = chunks,\n",
    "                                  embedding = embeddings,\n",
    "                                  persist_directory = path_chroma_db)\n",
    "\n",
    "chroma_db.persist() # for reproductibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayen\\AppData\\Local\\Temp\\ipykernel_101212\\791873308.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model = \"llama3\")\n",
      "C:\\Users\\mayen\\AppData\\Local\\Temp\\ipykernel_101212\\791873308.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  chorma_db_reloaded = Chroma(persist_directory = path_chroma_db, embedding_function = embeddings)\n"
     ]
    }
   ],
   "source": [
    "# modelisation\n",
    "llm = Ollama(model = \"llama3\")\n",
    "\n",
    "chorma_db_reloaded = Chroma(persist_directory = path_chroma_db, embedding_function = embeddings)\n",
    "retriever = chorma_db_reloaded.as_retriever(search_kwargs= {\"k\" : 3}) # fetch the 3 best chunks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Tu es un expert en politiques d'entreprise, ton rôle est de répondre aux questions des clients\n",
    "et visiteurs en utilisant UNIQUEMENT le contexte fourni ci-dessous.\n",
    "Si tu ne peux pas trouver la réponse dans le contexte, dis clairement que tu ne sais pas.\n",
    "Fournis une réponse complète et précise.\n",
    "\n",
    "CONTRXT:\n",
    "{context}\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs) :\n",
    "    \"\"\"\n",
    "    format fetched context\n",
    "    \"\"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\" : retriever | format_docs, \"question\" : RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        |StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question : Quelles sont les conditions de resiliation des abonnements pour les offres de 26 ans? ---\n",
      "\n",
      "--- Réponse du Chatbot ---\n",
      "\n",
      "Je ne vois pas d'information spécifique sur les offres de 26 ans dans le contexte fourni. Les conditions générales d'abonnement mentionnent les offres de 12 ou 24 mois, mais pas d'offre de 26 ans. Il est donc impossible pour moi de fournir des informations précises sur les conditions de résiliation pour ces offres.\n",
      "\n",
      "Si vous avez des questions sur les conditions de résiliation pour les offres de 12 ou 24 mois, je serais ravi de vous aider.\n"
     ]
    }
   ],
   "source": [
    "# test : \n",
    "\n",
    "question = \"Quelles sont les conditions de resiliation des abonnements pour les offres de 26 ans?\"\n",
    "\n",
    "print(f\"\\n--- Question : {question} ---\\n\")\n",
    "response = rag_chain.invoke(question)\n",
    "\n",
    "print(\"--- Réponse du Chatbot ---\\n\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
